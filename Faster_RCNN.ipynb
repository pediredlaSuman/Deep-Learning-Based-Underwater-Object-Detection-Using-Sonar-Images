{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3eeda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "import time\n",
    "from setuptools import Extension, dist, find_packages, setup\n",
    "\n",
    "import torch\n",
    "from torch.utils.cpp_extension import BuildExtension, CUDAExtension\n",
    "\n",
    "dist.Distribution().fetch_build_eggs(['Cython', 'numpy>=1.11.1'])\n",
    "import numpy as np  # noqa: E402, isort:skip\n",
    "from Cython.Build import cythonize  # noqa: E402, isort:skip\n",
    "\n",
    "\n",
    "def readme():\n",
    "    with open('README.md', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "\n",
    "MAJOR = 1\n",
    "MINOR = 0\n",
    "PATCH = ''\n",
    "SUFFIX = 'rc1'\n",
    "if PATCH:\n",
    "    SHORT_VERSION = '{}.{}.{}{}'.format(MAJOR, MINOR, PATCH, SUFFIX)\n",
    "else:\n",
    "    SHORT_VERSION = '{}.{}{}'.format(MAJOR, MINOR, SUFFIX)\n",
    "\n",
    "version_file = 'mmdet/version.py'\n",
    "\n",
    "\n",
    "def get_git_hash():\n",
    "\n",
    "    def _minimal_ext_cmd(cmd):\n",
    "        # construct minimal environment\n",
    "        env = {}\n",
    "        for k in ['SYSTEMROOT', 'PATH', 'HOME']:\n",
    "            v = os.environ.get(k)\n",
    "            if v is not None:\n",
    "                env[k] = v\n",
    "        # LANGUAGE is used on win32\n",
    "        env['LANGUAGE'] = 'C'\n",
    "        env['LANG'] = 'C'\n",
    "        env['LC_ALL'] = 'C'\n",
    "        out = subprocess.Popen(\n",
    "            cmd, stdout=subprocess.PIPE, env=env).communicate()[0]\n",
    "        return out\n",
    "\n",
    "    try:\n",
    "        out = _minimal_ext_cmd(['git', 'rev-parse', 'HEAD'])\n",
    "        sha = out.strip().decode('ascii')\n",
    "    except OSError:\n",
    "        sha = 'unknown'\n",
    "\n",
    "    return sha\n",
    "\n",
    "\n",
    "def get_hash():\n",
    "    if os.path.exists('.git'):\n",
    "        sha = get_git_hash()[:7]\n",
    "    elif os.path.exists(version_file):\n",
    "        try:\n",
    "            from mmdet.version import __version__\n",
    "            sha = __version__.split('+')[-1]\n",
    "        except ImportError:\n",
    "            raise ImportError('Unable to get git version')\n",
    "    else:\n",
    "        sha = 'unknown'\n",
    "\n",
    "    return sha\n",
    "\n",
    "\n",
    "def write_version_py():\n",
    "    content = \"\"\"# GENERATED VERSION FILE\n",
    "# TIME: {}\n",
    "\n",
    "__version__ = '{}'\n",
    "short_version = '{}'\n",
    "\"\"\"\n",
    "    sha = get_hash()\n",
    "    VERSION = SHORT_VERSION + '+' + sha\n",
    "\n",
    "    with open(version_file, 'w') as f:\n",
    "        f.write(content.format(time.asctime(), VERSION, SHORT_VERSION))\n",
    "\n",
    "\n",
    "def get_version():\n",
    "    with open(version_file, 'r') as f:\n",
    "        exec(compile(f.read(), version_file, 'exec'))\n",
    "    return locals()['__version__']\n",
    "\n",
    "\n",
    "def make_cuda_ext(name, module, sources):\n",
    "\n",
    "    define_macros = []\n",
    "\n",
    "    if torch.cuda.is_available() or os.getenv('FORCE_CUDA', '0') == '1':\n",
    "        define_macros += [(\"WITH_CUDA\", None)]\n",
    "    else:\n",
    "        raise EnvironmentError('CUDA is required to compile MMDetection!')\n",
    "\n",
    "    return CUDAExtension(\n",
    "        name='{}.{}'.format(module, name),\n",
    "        sources=[os.path.join(*module.split('.'), p) for p in sources],\n",
    "        define_macros=define_macros,\n",
    "        extra_compile_args={\n",
    "            'cxx': [],\n",
    "            'nvcc': [\n",
    "                '-D__CUDA_NO_HALF_OPERATORS__',\n",
    "                '-D__CUDA_NO_HALF_CONVERSIONS__',\n",
    "                '-D__CUDA_NO_HALF2_OPERATORS__',\n",
    "            ]\n",
    "        })\n",
    "\n",
    "\n",
    "def make_cython_ext(name, module, sources):\n",
    "    extra_compile_args = None\n",
    "    if platform.system() != 'Windows':\n",
    "        extra_compile_args = {\n",
    "            'cxx': ['-Wno-unused-function', '-Wno-write-strings']\n",
    "        }\n",
    "\n",
    "    extension = Extension(\n",
    "        '{}.{}'.format(module, name),\n",
    "        [os.path.join(*module.split('.'), p) for p in sources],\n",
    "        include_dirs=[np.get_include()],\n",
    "        language='c++',\n",
    "        extra_compile_args=extra_compile_args)\n",
    "    extension, = cythonize(extension)\n",
    "    return extension\n",
    "\n",
    "\n",
    "def get_requirements(filename='requirements.txt'):\n",
    "    here = os.path.dirname(os.path.realpath(__file__))\n",
    "    with open(os.path.join(here, filename), 'r') as f:\n",
    "        requires = [line.replace('\\n', '') for line in f.readlines()]\n",
    "    return requires\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    write_version_py()\n",
    "    setup(\n",
    "        name='mmdet',\n",
    "        version=get_version(),\n",
    "        description='Open MMLab Detection Toolbox and Benchmark',\n",
    "        long_description=readme(),\n",
    "        author='OpenMMLab',\n",
    "        author_email='chenkaidev@gmail.com',\n",
    "        keywords='computer vision, object detection',\n",
    "        url='https://github.com/open-mmlab/mmdetection',\n",
    "        packages=find_packages(exclude=('configs', 'tools', 'demo')),\n",
    "        package_data={'mmdet.ops': ['*/*.so']},\n",
    "        classifiers=[\n",
    "            'Development Status :: 4 - Beta',\n",
    "            'License :: OSI Approved :: Apache Software License',\n",
    "            'Operating System :: OS Independent',\n",
    "            'Programming Language :: Python :: 3',\n",
    "            'Programming Language :: Python :: 3.5',\n",
    "            'Programming Language :: Python :: 3.6',\n",
    "            'Programming Language :: Python :: 3.7',\n",
    "        ],\n",
    "        license='Apache License 2.0',\n",
    "        setup_requires=['pytest-runner', 'cython', 'numpy'],\n",
    "        tests_require=['pytest', 'xdoctest', 'asynctest'],\n",
    "        install_requires=get_requirements(),\n",
    "        ext_modules=[\n",
    "            make_cuda_ext(\n",
    "                name='compiling_info',\n",
    "                module='mmdet.ops.utils',\n",
    "                sources=['src/compiling_info.cpp']),\n",
    "            make_cython_ext(\n",
    "                name='soft_nms_cpu',\n",
    "                module='mmdet.ops.nms',\n",
    "                sources=['src/soft_nms_cpu.pyx']),\n",
    "            make_cuda_ext(\n",
    "                name='nms_cpu',\n",
    "                module='mmdet.ops.nms',\n",
    "                sources=['src/nms_cpu.cpp']),\n",
    "            make_cuda_ext(\n",
    "                name='nms_cuda',\n",
    "                module='mmdet.ops.nms',\n",
    "                sources=['src/nms_cuda.cpp', 'src/nms_kernel.cu']),\n",
    "            make_cuda_ext(\n",
    "                name='roi_align_cuda',\n",
    "                module='mmdet.ops.roi_align',\n",
    "                sources=['src/roi_align_cuda.cpp', 'src/roi_align_kernel.cu']),\n",
    "            make_cuda_ext(\n",
    "                name='roi_pool_cuda',\n",
    "                module='mmdet.ops.roi_pool',\n",
    "                sources=['src/roi_pool_cuda.cpp', 'src/roi_pool_kernel.cu']),\n",
    "            make_cuda_ext(\n",
    "                name='deform_conv_cuda',\n",
    "                module='mmdet.ops.dcn',\n",
    "                sources=[\n",
    "                    'src/deform_conv_cuda.cpp',\n",
    "                    'src/deform_conv_cuda_kernel.cu'\n",
    "                ]),\n",
    "            make_cuda_ext(\n",
    "                name='deform_pool_cuda',\n",
    "                module='mmdet.ops.dcn',\n",
    "                sources=[\n",
    "                    'src/deform_pool_cuda.cpp',\n",
    "                    'src/deform_pool_cuda_kernel.cu'\n",
    "                ]),\n",
    "            make_cuda_ext(\n",
    "                name='sigmoid_focal_loss_cuda',\n",
    "                module='mmdet.ops.sigmoid_focal_loss',\n",
    "                sources=[\n",
    "                    'src/sigmoid_focal_loss.cpp',\n",
    "                    'src/sigmoid_focal_loss_cuda.cu'\n",
    "                ]),\n",
    "            make_cuda_ext(\n",
    "                name='masked_conv2d_cuda',\n",
    "                module='mmdet.ops.masked_conv',\n",
    "                sources=[\n",
    "                    'src/masked_conv2d_cuda.cpp', 'src/masked_conv2d_kernel.cu'\n",
    "                ]),\n",
    "        ],\n",
    "        cmdclass={'build_ext': BuildExtension},\n",
    "        zip_safe=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# Load a pre-trained Faster R-CNN model\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# Get the number of input features for the classifier\n",
    "num_classes = 3  # Change this based on the number of classes (e.g., fish, coral, debris)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# Replace the head of the Faster R-CNN model with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f762939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms (e.g., resizing and normalizing)\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load the dataset\n",
    "dataset = UnderwaterDataset(root='dataset/train', transforms=transform)\n",
    "dataset_val = UnderwaterDataset(root='dataset/val', transforms=transform)\n",
    "\n",
    "# Data loaders\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "data_loader_val = torch.utils.data.DataLoader(dataset_val, batch_size=2, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "# Set the device (use GPU if available)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# Train for multiple epochs\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74b1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    i = 0\n",
    "    for images, targets in data_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # Forward pass\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}], Step [{i}], Loss: {losses.item()}\")\n",
    "        i += 1\n",
    "\n",
    "    # Update learning rate\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader_val:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            output = model(images, targets)\n",
    "\n",
    "            # Here you can calculate mAP or loss on validation set\n",
    "            print(\"Validation output:\", output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
